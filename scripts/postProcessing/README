############################################################################

SHOCK TUBE 

Post processing for quantitative comparison of simulation results with exact
solution 

############################################################################

for results obtained with 1D particle distribution
--------------------------------------------------




for results obtained with 2D particle distribution
--------------------------------------------------

a rough overview on what has to be done:
---------------- 

- process the file containing the initial (at t=0) particle data as
  information on initial particle positons will be needed to average the
  simulation results

- average the simulation results in the second (y) direction

- compute exact results for shock tube problem at the (averaged) particle
  positions

- compare exact and simulation results

now in detail
-------------

1. run the shell script <<processAndSort00000000.sh>> in this
(/sph-blitz/scripts/postProcessing) directory

This will perform the following actions:

 - create a directory <<ResultsInProgress>> in sph-blitz/results
   !!!ATTENTION!!! by running this script all data possibly already existing
   in the <<ResultsInProgress>> directory will be deleted. Therefore be sure
   to save them at a different location before!!!

 - read the file <<prtl00000000.dat>> from <<the sph-blitz/src/outdata>>
   directory, cut the file header off and sort the file on the x values of all
   particles (corresponds to values in first column).

 - write the sorted data into the file <<sorted00000000.dat>> in the
   <<ResultsInProgress>> directory

   Note: this action is necessary in preparation for the calculation of the
   exact shock tube results: those will later be calculated by another program
   exactly at the particle positions issued from the simulation results. 
   For the 2D particle distribution, all particles initially (at t=0) having
   the same x position will therefore be averaged to give the representative
   values for 1D comparison. 
   The sorting of particles is needed for the later averaging algorithm.

2. also in this local directory: run the c++ program <<average_q1DResults.cpp>>
    (possibly need to compile (make) before)

 This will perform the following actions:

 - read the <<sorted00000000.dat>> data from file and delete all boundary
   (virtual) particles (characterized by their ID=0)

 - determine all particle ensembles which have the same x position and save
   their respective IDs

 - ask the user for the name of the file to average, read this file 
   (from xxx/src/outdata), delete all boundary particles, and average
    corresponding particles (based on their IDs as previously determined)

 - write the averaged results into the file
    <<results/ResultsInProgress/averagedxxxxxxxx.dat>> 
   (where xxxxxxxx represents the corresponding simulation time in ms)
